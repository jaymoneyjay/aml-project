{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3979addb",
   "metadata": {},
   "source": [
    "# Build model for different features\n",
    "- HB Features\n",
    "- Delineation Features\n",
    "- HRV Features\n",
    "- CNN Features"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 70,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "id": "7a6e67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set('talk')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6cd75d",
   "metadata": {},
   "source": [
    "Read in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da2b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/hoga/eth/aml/aml-project/task2/data/'\n",
    "\n",
    "X_train_hb = pd.read_csv(path+'features_heartbeat_train.csv').values\n",
    "X_test_hb = pd.read_csv(path+'features_heartbeat_test.csv').values\n",
    "\n",
    "X_train_cwt = pd.read_csv(path+'features_cwt_train.csv').values[:,1:] # skip index col]\n",
    "X_test_cwt = pd.read_csv(path+'features_cwt_test.csv').values[:,1:] # skip index col]\n",
    "\n",
    "X_train_fft = pd.read_csv(path+'features_train_fft.csv').values[:,1:] # skip index col\n",
    "X_test_fft = pd.read_csv(path+'features_test_fft.csv').values[:,1:] #skip index col\n",
    "\n",
    "X_train_delin = pd.read_csv(path+'features_delineation_train.csv')\n",
    "X_test_delin = pd.read_csv(path+'features_delineation_test.csv')\n",
    "\n",
    "X_train_hrv = pd.read_csv(path+'features_hrv_train.csv')\n",
    "X_test_hrv = pd.read_csv(path+'features_hrv_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffefc7",
   "metadata": {},
   "source": [
    "Read in target"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 83,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "id": "7cef2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('../../task2/y_train.csv').y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 84,
   "id": "d63471f5",
=======
   "execution_count": 4,
   "id": "96955d72",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117,)"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 84,
=======
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ef8190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 5,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "y_train.shape"
=======
    "y_train"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c4ac7",
   "metadata": {},
   "source": [
    "Join feature matrices"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 85,
   "id": "e787b2b1",
=======
   "execution_count": 6,
   "id": "8195317d",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = np.hstack([X_train_hb, X_train_delin, X_train_hrv, X_train_fft, X_train_cwt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce78b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full = np.hstack([X_test_hb, X_test_delin, X_test_hrv, X_test_fft, X_test_cwt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf4d28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3411, 1071)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 76,
   "id": "7127823d",
=======
   "execution_count": 9,
   "id": "f190ce8d",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 1071)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "# don't need to apply train / test split if we use gridsearchcv\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, target, random_state=0, train_size=train_size, stratify=target)"
=======
    "X_train_full.shape"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b60b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = XGBClassifier(learning_rate=0.05, n_estimators=500, max_depth=5)\n",
    "\n",
    "clf2 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=600, max_depth=7, \n",
    "                                 min_samples_split=60, min_samples_leaf=9, subsample=1.0,\n",
    "                                 random_state=0)\n",
    "param_grid = {\n",
    "    'imputer': [SimpleImputer(strategy='constant', fill_value=0, add_indicator=True)],\n",
    "    'scaler': [RobustScaler()],\n",
    "    'clf': [clf2],\n",
    "    'clf__max_features': [400]\n",
    "    \n",
    "}\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('threshold', VarianceThreshold()),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "    ])\n",
    "\n",
    "#param_grid = {\n",
    "#    'imputer': [SimpleImputer(strategy='constant', fill_value=0, add_indicator=True)],\n",
    "#    'scaler': [RobustScaler()],\n",
    "#    'selector': [SelectKBest()],\n",
    "#    'selector__k': [10, 50, 200, 500],\n",
    "#    'pca': [KernelPCA()],\n",
    "#    'pca__n_components': [50, 100, 300],\n",
    "#    'clf': [clf2],\n",
    "#    'clf__max_features': [10, 50, 100, 400]\n",
    "#    \n",
    "#}\n",
    "#pipeline = Pipeline(steps=[\n",
    "#    ('imputer', SimpleImputer()),\n",
    "#    ('scaler', RobustScaler()),\n",
    "#    ('threshold', VarianceThreshold()),\n",
    "#    ('selector', SelectKBest()),\n",
    "#    ('pca', KernelPCA()),\n",
    "#    ('clf', XGBClassifier())\n",
    "#    ])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 77,
   "id": "20b0df6e",
=======
   "execution_count": 11,
   "id": "5622a71e",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 78,
   "id": "a661a0ab",
=======
   "execution_count": 12,
   "id": "e9ece5a3",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1_micro', cv=cv, verbose=10) # stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da52b092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3; 1/1] START clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler()\n",
      "[CV 1/3; 1/1] END clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler();, score=0.801 total time=23.7min\n",
      "[CV 2/3; 1/1] START clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler()\n",
      "[CV 2/3; 1/1] END clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler();, score=0.801 total time=13.6min\n",
      "[CV 3/3; 1/1] START clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler()\n",
      "[CV 3/3; 1/1] END clf=GradientBoostingClassifier(learning_rate=0.05, max_depth=7, min_samples_leaf=9,\n",
      "                           min_samples_split=60, n_estimators=600,\n",
      "                           random_state=0), clf__max_features=400, imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), scaler=RobustScaler();, score=0.803 total time=13.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                       ('scaler', RobustScaler()),\n",
       "                                       ('threshold', VarianceThreshold()),\n",
       "                                       ('clf', GradientBoostingClassifier())]),\n",
       "             param_grid={'clf': [GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                            max_depth=7,\n",
       "                                                            max_features=400,\n",
       "                                                            min_samples_leaf=9,\n",
       "                                                            min_samples_split=60,\n",
       "                                                            n_estimators=600,\n",
       "                                                            random_state=0)],\n",
       "                         'clf__max_features': [400],\n",
       "                         'imputer': [SimpleImputer(add_indicator=True,\n",
       "                                                   fill_value=0,\n",
       "                                                   strategy='constant')],\n",
       "                         'scaler': [RobustScaler()]},\n",
       "             scoring='f1_micro', verbose=10)"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 78,
=======
     "execution_count": 13,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_full, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 68,
   "id": "61bc1e38",
=======
   "execution_count": 14,
   "id": "96423914",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=True, fill_value=0,\n",
       "                               strategy='constant')),\n",
       "                ('scaler', RobustScaler()), ('threshold', VarianceThreshold()),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.05, max_depth=7,\n",
       "                                            max_features=400,\n",
       "                                            min_samples_leaf=9,\n",
       "                                            min_samples_split=60,\n",
       "                                            n_estimators=600,\n",
       "                                            random_state=0))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 72,
   "id": "48207245",
=======
   "execution_count": 15,
   "id": "d4db4230",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.44440560340881"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total fit time in min\n",
    "grid.cv_results_['mean_fit_time'].sum()/60+grid.refit_time_/60"
   ]
  },
  {
<<<<<<< Updated upstream
   "cell_type": "markdown",
   "id": "86463273",
=======
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e153d8",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1020.84884667]),\n",
       " 'std_fit_time': array([283.76980119]),\n",
       " 'mean_score_time': array([0.2732935]),\n",
       " 'std_score_time': array([0.06628687]),\n",
       " 'param_clf': masked_array(data=[GradientBoostingClassifier(learning_rate=0.05, max_depth=7, max_features=400,\n",
       "                                               min_samples_leaf=9, min_samples_split=60,\n",
       "                                               n_estimators=600, random_state=0)                 ],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__max_features': masked_array(data=[400],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_imputer': masked_array(data=[SimpleImputer(add_indicator=True, fill_value=0, strategy='constant')],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_scaler': masked_array(data=[RobustScaler()],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf': GradientBoostingClassifier(learning_rate=0.05, max_depth=7, max_features=400,\n",
       "                              min_samples_leaf=9, min_samples_split=60,\n",
       "                              n_estimators=600, random_state=0),\n",
       "   'clf__max_features': 400,\n",
       "   'imputer': SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'),\n",
       "   'scaler': RobustScaler()}],\n",
       " 'split0_test_score': array([0.80128957]),\n",
       " 'split1_test_score': array([0.80128957]),\n",
       " 'split2_test_score': array([0.80293255]),\n",
       " 'mean_test_score': array([0.80183723]),\n",
       " 'std_test_score': array([0.00077451]),\n",
       " 'rank_test_score': array([1], dtype=int32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 74,
   "id": "9cf54f5f",
=======
   "execution_count": 17,
   "id": "d4b3310a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018372279310902"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 92,
   "id": "8b60b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = XGBClassifier(learning_rate=0.05, n_estimators=300, max_depth=5)\n",
    "\n",
    "clf2 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=500, max_depth=7, \n",
    "                                 min_samples_split=60, min_samples_leaf=9, subsample=1.0,\n",
    "                                 max_features=50, random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'imputer': [SimpleImputer(strategy='constant', fill_value=0, add_indicator=True)],\n",
    "    'scaler': [RobustScaler()],\n",
    "    'selector': [SelectKBest()],\n",
    "    'selector__k': [5, 10, 50],\n",
    "    'pca': [KernelPCA()],\n",
    "    'pca__n_components': [5, 10, 50],\n",
    "    'clf': [clf1],\n",
    "}"
=======
   "execution_count": 18,
   "id": "c774c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test_full)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "f9fd86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add VarianceThreshold, we got constant features (nan to zero)\n",
    "#962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956"
=======
   "execution_count": 19,
   "id": "a752218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'results_gradboost_maxfeat_allfeat_maxFeat400.csv'"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 93,
   "id": "fbfa4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('threshold', VarianceThreshold()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('pca', KernelPCA()),\n",
    "    ('clf', XGBClassifier())\n",
    "    ])"
=======
   "execution_count": 20,
   "id": "e131cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'id': np.arange(len(y_pred)), 'y': y_pred.ravel()})\n",
    "df_res.to_csv(f'submissions/{file_name}', header=True, index=False)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 94,
   "id": "e9ece5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1_micro', cv=5, verbose=10)"
=======
   "execution_count": 21,
   "id": "aaf9ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_valid = grid.best_estimator_.predict(X_valid)\n",
    "#f1_score_micro = f1_score(y_true=y_valid, y_pred=y_pred_valid, average='micro')\n",
    "#print(f1_score_micro)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "44d213df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:55:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 1/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.688 total time=  58.8s\n",
      "[CV 2/5; 1/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:56:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 1/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.680 total time= 1.4min\n",
      "[CV 3/5; 1/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:57:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 1/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.701 total time= 1.4min\n",
      "[CV 4/5; 1/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:59:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 1/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.709 total time= 1.5min\n",
      "[CV 5/5; 1/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:00:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 1/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.709 total time= 1.4min\n",
      "[CV 1/5; 2/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:02:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 2/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.674 total time= 1.5min\n",
      "[CV 2/5; 2/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:03:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 2/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.703 total time= 1.3min\n",
      "[CV 3/5; 2/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:04:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 2/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.694 total time= 1.2min\n",
      "[CV 4/5; 2/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:06:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 2/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.664 total time=  58.0s\n",
      "[CV 5/5; 2/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:07:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 2/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.663 total time= 1.2min\n",
      "[CV 1/5; 3/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:08:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 3/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.652 total time= 1.4min\n",
      "[CV 2/5; 3/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:09:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 3/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.631 total time= 1.4min\n",
      "[CV 3/5; 3/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:11:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 3/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.642 total time= 1.9min\n",
      "[CV 4/5; 3/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:12:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 3/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.646 total time= 1.2min\n",
      "[CV 5/5; 3/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:14:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 3/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=5, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.641 total time= 1.6min\n",
      "[CV 1/5; 4/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:16:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 4/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.688 total time= 2.6min\n",
      "[CV 2/5; 4/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:19:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 4/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.680 total time= 3.0min\n",
      "[CV 3/5; 4/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:22:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 4/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.701 total time= 3.0min\n",
      "[CV 4/5; 4/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 4/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.709 total time= 5.8min\n",
      "[CV 5/5; 4/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:34:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 4/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=5;, score=0.709 total time= 5.7min\n",
      "[CV 1/5; 5/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:40:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 5/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.704 total time= 9.1min\n",
      "[CV 2/5; 5/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:51:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 5/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.732 total time=11.2min\n",
      "[CV 3/5; 5/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:03:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 5/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.720 total time=11.9min\n",
      "[CV 4/5; 5/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:13:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 5/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.718 total time= 9.6min\n",
      "[CV 5/5; 5/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:21:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 5/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=10;, score=0.719 total time= 7.8min\n",
      "[CV 1/5; 6/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1951 1952 1953 1954 1955 1956\n",
      " 1969 1970] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:29:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 6/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.678 total time=10.5min\n",
      "[CV 2/5; 6/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 962  963  964  965  966  967  980  981 1051 1052 1053 1054 1055 1056\n",
      " 1069 1070] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/home/rapwag01/.virtualenvs/vethaml/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:40:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 6/9] END clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50;, score=0.692 total time=10.2min\n",
      "[CV 3/5; 6/9] START clf=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), imputer=SimpleImputer(add_indicator=True, fill_value=0, strategy='constant'), pca=KernelPCA(), pca__n_components=10, scaler=RobustScaler(), selector=SelectKBest(), selector__k=50\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train_full, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd43523f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', RobustScaler()),\n",
       "                ('selector', SelectKBest(k=100)),\n",
       "                ('pca', KernelPCA(n_components=50)),\n",
       "                ('clf',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=7,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=500,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6589221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.13453327814737"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total fit time in min\n",
    "grid.cv_results_['mean_fit_time'].sum()/60+grid.refit_time_/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f420034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([355.32276225, 352.91089821, 360.78657513, 446.23621502,\n",
       "        542.56032243, 492.97693124]),\n",
       " 'std_fit_time': array([ 7.37814669,  2.24550966,  3.57112282,  3.5199128 ,  2.80051938,\n",
       "        35.66951078]),\n",
       " 'mean_score_time': array([0.36865253, 0.2251111 , 0.27229733, 0.24745607, 0.3048562 ,\n",
       "        0.29407144]),\n",
       " 'std_score_time': array([0.15649779, 0.02188388, 0.03999984, 0.02521694, 0.03070745,\n",
       "        0.02930795]),\n",
       " 'param_clf': masked_array(data=[XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ,\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ,\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ,\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ,\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ,\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                                  colsample_bynode=None, colsample_bytree=None,\n",
       "                                  enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                                  importance_type=None, interaction_constraints=None,\n",
       "                                  learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                                  min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                                  n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                                  predictor=None, random_state=None, reg_alpha=None,\n",
       "                                  reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                                  tree_method=None, validate_parameters=None, verbosity=None)   ],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__max_depth': masked_array(data=[7, 7, 7, 7, 7, 7],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_imputer': masked_array(data=[SimpleImputer(), SimpleImputer(), SimpleImputer(),\n",
       "                    SimpleImputer(), SimpleImputer(), SimpleImputer()],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_pca': masked_array(data=[KernelPCA(n_components=50), KernelPCA(n_components=50),\n",
       "                    KernelPCA(n_components=50), KernelPCA(n_components=50),\n",
       "                    KernelPCA(n_components=50), KernelPCA(n_components=50)],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_pca__n_components': masked_array(data=[50, 50, 50, 400, 400, 400],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_scaler': masked_array(data=[RobustScaler(), RobustScaler(), RobustScaler(),\n",
       "                    RobustScaler(), RobustScaler(), RobustScaler()],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_selector': masked_array(data=[SelectKBest(k=100), SelectKBest(k=100),\n",
       "                    SelectKBest(k=100), SelectKBest(k=100),\n",
       "                    SelectKBest(k=100), SelectKBest(k=100)],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_selector__k': masked_array(data=[100, 300, 500, 100, 300, 500],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 50,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 100},\n",
       "  {'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 50,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 300},\n",
       "  {'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 50,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 500},\n",
       "  {'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 400,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 100},\n",
       "  {'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 400,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 300},\n",
       "  {'clf': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None,\n",
       "                 enable_categorical=False, gamma=None, gpu_id=None,\n",
       "                 importance_type=None, interaction_constraints=None,\n",
       "                 learning_rate=0.05, max_delta_step=None, max_depth=7,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None),\n",
       "   'clf__learning_rate': 0.05,\n",
       "   'clf__max_depth': 7,\n",
       "   'clf__n_estimators': 500,\n",
       "   'imputer': SimpleImputer(),\n",
       "   'pca': KernelPCA(n_components=50),\n",
       "   'pca__n_components': 400,\n",
       "   'scaler': RobustScaler(),\n",
       "   'selector': SelectKBest(k=100),\n",
       "   'selector__k': 500}],\n",
       " 'split0_test_score': array([0.75457875, 0.73137973, 0.75213675, 0.75946276, 0.74725275,\n",
       "        0.73626374]),\n",
       " 'split1_test_score': array([0.72405372, 0.73382173, 0.72161172, 0.71672772, 0.73137973,\n",
       "        0.73260073]),\n",
       " 'split2_test_score': array([0.76190476, 0.72893773, 0.72283272, 0.74725275, 0.72405372,\n",
       "        0.74847375]),\n",
       " 'split3_test_score': array([0.74449878, 0.75183374, 0.75305623, 0.74205379, 0.74694377,\n",
       "        0.73471883]),\n",
       " 'split4_test_score': array([0.72616137, 0.73716381, 0.72493888, 0.72127139, 0.73471883,\n",
       "        0.71882641]),\n",
       " 'mean_test_score': array([0.74223948, 0.73662735, 0.73491526, 0.73735368, 0.73686976,\n",
       "        0.73417669]),\n",
       " 'std_test_score': array([0.01505532, 0.00807541, 0.01447878, 0.01608082, 0.0090367 ,\n",
       "        0.00945696]),\n",
       " 'rank_test_score': array([1, 4, 5, 2, 3, 6], dtype=int32)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0cd51d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', RobustScaler()),\n",
       "                ('selector', SelectKBest(k=100)),\n",
       "                ('pca', KernelPCA(n_components=50)),\n",
       "                ('clf',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=7,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=500,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b9e2ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422394774473015"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8a582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d7199c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'results_first_run_partdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7489b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'id': np.arange(len(y_pred)), 'y': y_pred.ravel()})\n",
    "df_res.to_csv(f'submissions/{file_name}', header=True, index=False)"
   ]
=======
   "id": "0c13e37d",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
