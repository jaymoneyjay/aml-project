{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from functools import partial\n",
    "from aml_project import utils\n",
    "from aml_project.models import BaseModule\n",
    "from aml_project import trainer\n",
    "import biosppy.signals.ecg as ecg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "from skorch.dataset import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring, Initializer, LRScheduler, TensorBoard\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer\n",
    "import sklearn\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pywt\n",
    "import cv2\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(data, idx, vlines=[], titles=[]):\n",
    "    \n",
    "    if type(idx) == int:\n",
    "        idx = range(idx)\n",
    "        \n",
    "    width = 20\n",
    "    ncols = 1\n",
    "    if len(data.shape) > 2:\n",
    "        ncols = 5\n",
    "        width = 2\n",
    "        \n",
    "    nrows = len(idx) // ncols\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*width, nrows*5))\n",
    "    if len(idx) > 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "    for i, ax in enumerate(axes):\n",
    "        if len(data.shape) > 2:\n",
    "            ax.imshow(data[i][0])\n",
    "        else:\n",
    "            measurements = data.iloc[i].dropna().to_numpy(dtype='float32')\n",
    "            #measurements = measurements[0:-1:10]\n",
    "            measurements /= 1000\n",
    "            seconds = np.arange(0, len(measurements)) / 30\n",
    "            ax.plot(seconds, measurements)\n",
    "            for line in vlines:\n",
    "                ax.axvline(x=(line/30))\n",
    "        if len(titles) > 0:\n",
    "            ax.set_title(titles[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train = utils.load_df('data', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.2 s, sys: 841 ms, total: 36 s\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = pd.read_csv('data/X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.4 s, sys: 357 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = pd.read_csv('data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 ms, sys: 618 Âµs, total: 2.1 ms\n",
      "Wall time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "3406    3406\n",
       "3407    3407\n",
       "3408    3408\n",
       "3409    3409\n",
       "3410    3410\n",
       "Name: id, Length: 3411, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.pop('id')\n",
    "X_test.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jodok/02 Code/spring21-JodokVieli/venv/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "/Users/jodok/02 Code/spring21-JodokVieli/venv/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1368: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(\n"
     ]
    }
   ],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "X_scaled = pd.DataFrame(robust_scaler.fit_transform(X))\n",
    "X_test_scaled = pd.DataFrame(robust_scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(source_x, source_y=None, sampling_rate=150, wavelet='mexh', thresh=0.2, dims=(100, 100), train=True, n_samples=0):\n",
    "    before, after = 90, 110\n",
    "    groups= []\n",
    "    if type(source_x) == str:\n",
    "        df_x = pd.read_csv(source_x)\n",
    "    else:\n",
    "        df_x = source_x\n",
    "        \n",
    "\n",
    "\n",
    "    if n_samples > 0:\n",
    "            df_x = df_x.iloc[:n_samples]\n",
    "        \n",
    "    scales = pywt.central_frequency(wavelet) * sampling_rate / np.arange(1, dims[0] + 1, 1)\n",
    "    \n",
    "    if train:\n",
    "        if type(source_y) == str:\n",
    "            arr_y = pd.read_csv(source_y).y.values\n",
    "        else:\n",
    "            arr_y = source_y.y.values\n",
    "\n",
    "    x_cwt_train, x_rr_train, y_train = [], [], []\n",
    "\n",
    "    # do not iterate over id (idx=0)\n",
    "    for j in tqdm(range(len(df_x)), leave=False):\n",
    "        signal = df_x.iloc[j].dropna()    \n",
    "        coefs, freq = pywt.cwt(signal, scales, wavelet, 1.0 / sampling_rate)\n",
    "        rpeaks = ecg.engzee_segmenter(signal, sampling_rate, threshold=thresh)['rpeaks']\n",
    "        \n",
    "        avg_rri = np.mean(np.diff(rpeaks))\n",
    "        \n",
    "        x_cwt, x_rr, y = [], [], []\n",
    "        for i in range(len(rpeaks)):\n",
    "            if i == 0 or i == len(rpeaks) - 1:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            \n",
    "            x_cwt.append(\n",
    "                cv2.resize(coefs[:, max(rpeaks[i] - before, 0):min(rpeaks[i] + after, coefs.shape[1])], dims)\n",
    "            )\n",
    "            x_rr.append([\n",
    "                rpeaks[i] - rpeaks[i - 1] - avg_rri,  # previous RR Interval\n",
    "                rpeaks[i + 1] - rpeaks[i] - avg_rri,  # post RR Interval\n",
    "                (rpeaks[i] - rpeaks[i - 1]) / (rpeaks[i + 1] - rpeaks[i]),  # ratio RR Interval\n",
    "                np.mean(np.diff(rpeaks[np.maximum(i - 10, 0):i + 1])) - avg_rri  # local RR Interval\n",
    "            ])\n",
    "            \n",
    "            if train:\n",
    "                y.append(arr_y[j])\n",
    "                \n",
    "            groups.append(j)\n",
    "        \n",
    "        x_cwt_train.append(x_cwt)\n",
    "        x_rr_train.append(x_rr)\n",
    "        \n",
    "        if train:\n",
    "            y_train.append(y)\n",
    "    \n",
    "    x_cwt_train = np.expand_dims(np.concatenate(x_cwt_train, axis=0), axis=1).astype(np.float32)\n",
    "    x_rr_train = np.concatenate(x_rr_train, axis=0).astype(np.float32)\n",
    "    #x_rr_train = RobustScaler().fit_transform(x_rr_train)\n",
    "    \n",
    "    if train:\n",
    "        y_train = np.concatenate(y_train, axis=0).astype(np.int64)\n",
    "        return x_cwt_train, x_rr_train, y_train, np.array(groups).astype(np.int64)\n",
    "    \n",
    "    return x_cwt_train, x_rr_train, np.array(groups).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 28s, sys: 49.1 s, total: 11min 17s\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_cwt, x_rr, y_segmented, groups = load_data(X_scaled, y, n_samples=0, dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler_rr = RobustScaler()\n",
    "x_rr = robust_scaler_rr.fit_transform(x_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 58s, sys: 40.4 s, total: 7min 38s\n",
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_cwt_test, x_rr_test, groups_test = load_data(X_test_scaled, train=False, n_samples=0, dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rr_test = robust_scaler_rr.transform(x_rr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features\n",
    "def aggregate_features(x_cwt, x_rr, groups):\n",
    "    features_cwt = []\n",
    "    features_rr = []\n",
    "    \n",
    "    for g in tqdm(np.unique(groups)):\n",
    "        idx_group = np.where(groups == g)[0]\n",
    "        \n",
    "        x_cwt_mean = np.mean(x_cwt[idx_group], axis=0)\n",
    "        x_cwt_med = np.median(x_cwt[idx_group], axis=0)\n",
    "        x_cwt_std = np.std(x_cwt[idx_group], axis=0)\n",
    "        x_cwt_min = np.min(x_cwt[idx_group], axis=0)\n",
    "        x_cwt_max = np.max(x_cwt[idx_group], axis=0)\n",
    "    \n",
    "        x_rr_mean = np.mean(x_rr[idx_group], axis=0)\n",
    "        x_rr_med = np.median(x_rr[idx_group], axis=0)\n",
    "        x_rr_std = np.std(x_rr[idx_group], axis=0)\n",
    "        x_rr_min = np.min(x_rr[idx_group], axis=0)\n",
    "        x_rr_max = np.max(x_rr[idx_group], axis=0)\n",
    "        \n",
    "        \n",
    "    \n",
    "        agg_cwt = np.concatenate([\n",
    "            x_cwt_mean,\n",
    "            x_cwt_med,\n",
    "            x_cwt_std,\n",
    "            x_cwt_min,\n",
    "            x_cwt_max\n",
    "        ])\n",
    "        \n",
    "        agg_rr = np.concatenate([\n",
    "            x_rr_mean,\n",
    "            x_rr_med,\n",
    "            x_rr_std,\n",
    "            x_rr_min,\n",
    "            x_rr_max,\n",
    "        ])\n",
    "        \n",
    "        features_cwt.append(agg_cwt)\n",
    "        features_rr.append(agg_rr)\n",
    "    \n",
    "    return np.stack(features_cwt), np.stack(features_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5117/5117 [00:52<00:00, 97.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 s, sys: 6 s, total: 40.1 s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_features_cwt, x_features_rr = aggregate_features(x_cwt, x_rr, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, n_classes=4):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(5, 16, 7)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pooling1 = nn.MaxPool2d(5)\n",
    "        self.pooling2 = nn.MaxPool2d(3)\n",
    "        self.pooling3 = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(84, 32)\n",
    "        self.fc2 = nn.Linear(32, n_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = F.relu(self.bn1(self.conv1(x1)))  # (16 x 94 x 94)\n",
    "        x1 = self.pooling1(x1)  # (16 x 18 x 18)\n",
    "        x1 = F.relu(self.bn2(self.conv2(x1)))  # (32 x 16 x 16)\n",
    "        x1 = self.pooling2(x1)  # (32 x 5 x 5)\n",
    "        x1 = F.relu(self.bn3(self.conv3(x1)))  # (64 x 3 x 3)\n",
    "        x1 = self.pooling3(x1)  # (64 x 1 x 1)\n",
    "        x1 = x1.view((-1, 64))  # (64,)\n",
    "        x = torch.cat((x1, x2), dim=1)  # (68,)\n",
    "        x = F.relu(self.fc1(x))  # (32,)\n",
    "        x = self.fc2(x)  # (4,)\n",
    "        #x = F.softmax(x, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule2(MyModule):\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x1 = F.relu(self.bn1(self.conv1(x1)))  # (16 x 94 x 94)\n",
    "        x1 = self.pooling1(x1)  # (16 x 18 x 18)\n",
    "        x1 = F.relu(self.bn2(self.conv2(x1)))  # (32 x 16 x 16)\n",
    "        x1 = self.pooling2(x1)  # (32 x 5 x 5)\n",
    "        x1 = F.relu(self.bn3(self.conv3(x1)))  # (64 x 3 x 3)\n",
    "        x1 = self.pooling3(x1)  # (64 x 1 x 1)\n",
    "        x1 = x1.view((-1, 64))  # (64,)\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    Initializer(\"[conv|fc]*.weight\", fn=torch.nn.init.kaiming_normal_),\n",
    "    Initializer(\"[conv|fc]*.bias\", fn=partial(torch.nn.init.constant_, val=0.0)),\n",
    "    LRScheduler(policy=StepLR, step_size=5, gamma=0.1),\n",
    "    EpochScoring(scoring=make_scorer(f1_score, average=\"micro\"), lower_is_better=False, name=\"valid_f1\"),\n",
    "    #TensorBoard(SummaryWriter(log_dir))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4222, 2.8877, 0.8679, 7.5250])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class = y.y.values\n",
    "class_weight = compute_class_weight('balanced', classes=np.unique(y_class), y=y_class)\n",
    "class_weight = torch.Tensor(class_weight)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skorch.dataset.Dataset at 0x7f80a803a340>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset({\"x1\": x_features_cwt, \"x2\": x_features_rr}, y.y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = partial(train_test_split, stratify=y_class)(Dataset({'x1': x_features_cwt, 'x2': x_features_rr}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, t = dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': array([[[-2.29244614e+00, -2.50761533e+00, -2.73225975e+00, ...,\n",
       "           1.88356388e+00,  2.32507968e+00,  2.71261358e+00],\n",
       "         [ 3.19632119e-03, -2.50800401e-02, -6.01410381e-02, ...,\n",
       "           3.33174777e+00,  3.15874457e+00,  2.91274261e+00],\n",
       "         [ 9.67028663e-02,  1.74440239e-02, -5.72906695e-02, ...,\n",
       "           2.79925561e+00,  2.50689006e+00,  2.11114812e+00],\n",
       "         ...,\n",
       "         [-9.25757398e-04, -2.68174830e-04,  1.46057209e-04, ...,\n",
       "          -6.81502046e-04, -1.39414833e-03, -1.04429096e-03],\n",
       "         [-6.46477041e-04, -2.83535104e-04,  4.99769121e-05, ...,\n",
       "          -1.56135589e-04, -7.09823275e-04, -4.88170335e-04],\n",
       "         [-3.77852208e-04, -3.15230689e-04, -5.32163504e-05, ...,\n",
       "           4.09840140e-04, -1.12879626e-07,  9.90527624e-05]],\n",
       " \n",
       "        [[-1.63774180e+00, -1.80931246e+00, -2.13428831e+00, ...,\n",
       "           1.78994691e+00,  2.19521570e+00,  2.53423905e+00],\n",
       "         [ 3.50721972e-03, -2.42443215e-02, -8.03907961e-02, ...,\n",
       "           3.67372251e+00,  3.57351851e+00,  3.30215645e+00],\n",
       "         [ 1.22663431e-01,  2.78278720e-02, -8.01002383e-02, ...,\n",
       "           2.82030773e+00,  2.58330345e+00,  2.19003248e+00],\n",
       "         ...,\n",
       "         [-6.03530032e-04, -2.83654546e-04, -1.18112512e-04, ...,\n",
       "          -3.12085176e-04, -5.23743394e-04, -8.27922253e-04],\n",
       "         [-3.19216168e-04, -2.11857856e-04,  1.04198778e-04, ...,\n",
       "          -2.36186679e-05, -3.95802927e-04, -4.06911393e-04],\n",
       "         [-8.96175989e-05, -7.79931579e-05,  9.11045572e-05, ...,\n",
       "           2.88762676e-04,  2.22939816e-05,  1.63242948e-04]],\n",
       " \n",
       "        [[ 4.06696081e+00,  4.02257633e+00,  3.95943642e+00, ...,\n",
       "           1.19766676e+00,  1.23603821e+00,  1.36196148e+00],\n",
       "         [ 1.32724249e+00,  1.27311671e+00,  1.22643590e+00, ...,\n",
       "           2.09785509e+00,  2.28099179e+00,  2.44364738e+00],\n",
       "         [ 6.90048337e-01,  7.09489942e-01,  7.18036294e-01, ...,\n",
       "           6.71981454e-01,  7.58736968e-01,  8.83553207e-01],\n",
       "         ...,\n",
       "         [ 2.28120503e-03,  1.86414015e-03,  1.40974531e-03, ...,\n",
       "           2.03740830e-03,  2.69002980e-03,  2.17018067e-03],\n",
       "         [ 1.64078991e-03,  1.28651515e-03,  8.67229188e-04, ...,\n",
       "           1.01652276e-03,  1.85082096e-03,  1.37776393e-03],\n",
       "         [ 1.28365401e-03,  9.53675946e-04,  6.80010300e-04, ...,\n",
       "           1.00931118e-03,  1.22859899e-03,  9.23444983e-04]],\n",
       " \n",
       "        [[-2.06016960e+01, -2.07236214e+01, -2.07289829e+01, ...,\n",
       "          -1.60642052e+00, -6.49031222e-01,  2.02436298e-01],\n",
       "         [-3.66917348e+00, -3.28663087e+00, -2.97390556e+00, ...,\n",
       "          -7.78979921e+00, -8.85468960e+00, -9.82423973e+00],\n",
       "         [-9.00100648e-01, -1.14963186e+00, -1.41551220e+00, ...,\n",
       "           4.09960151e-01, -6.08161211e-01, -1.99409151e+00],\n",
       "         ...,\n",
       "         [-6.33484544e-03, -6.69386936e-03, -3.48628615e-03, ...,\n",
       "          -9.44779627e-03, -1.29930340e-02, -6.42139884e-03],\n",
       "         [-5.11890510e-03, -4.87364875e-03, -2.58693192e-03, ...,\n",
       "          -2.93040532e-03, -9.07831546e-03, -4.45740158e-03],\n",
       "         [-4.37827827e-03, -3.15001444e-03, -1.92539440e-03, ...,\n",
       "          -1.23150367e-03, -5.27137937e-03, -2.54830718e-03]],\n",
       " \n",
       "        [[ 2.95253181e+00,  2.63162780e+00,  2.28121281e+00, ...,\n",
       "           4.91155958e+00,  5.67185402e+00,  7.92463827e+00],\n",
       "         [ 5.17882204e+00,  5.27185917e+00,  5.27019405e+00, ...,\n",
       "           5.28282309e+00,  5.23443890e+00,  5.09437275e+00],\n",
       "         [ 3.30607700e+00,  3.24152517e+00,  3.10011816e+00, ...,\n",
       "           4.12144089e+00,  3.86913204e+00,  3.43989348e+00],\n",
       "         ...,\n",
       "         [ 5.70730167e-03,  3.42982565e-03,  3.09312576e-03, ...,\n",
       "           2.99815065e-03,  2.22036685e-03,  4.62952862e-03],\n",
       "         [ 3.25746182e-03,  2.88636237e-03,  1.63538929e-03, ...,\n",
       "           2.07186560e-03,  1.50616083e-03,  2.94890418e-03],\n",
       "         [ 1.64450193e-03,  2.43182224e-03,  8.55738530e-04, ...,\n",
       "           3.98326758e-03,  2.32876441e-03,  1.89045363e-03]]],\n",
       "       dtype=float32),\n",
       " 'x2': array([-0.07400715, -0.07714646,  0.21486212, -0.0262939 ,  0.30110484,\n",
       "         0.2992441 ,  0.06621947, -0.34253827,  0.9939576 ,  0.99734575,\n",
       "         2.9554892 ,  0.5782787 , -3.4393277 , -3.4539382 , -3.7446437 ,\n",
       "        -0.6367483 ,  0.71255237,  0.7120942 , 11.080641  ,  0.749308  ],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features_cwt_train, x_features_cwt_val, x_features_rr_train, x_features_rr_val, y_class_train, y_class_val = train_test_split(x_features_cwt, x_features_rr, y_class, stratify=y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3837, 5, 100, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features_cwt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NeuralNetClassifier(  # skorch is extensive package of pytorch for compatible with scikit-learn\n",
    "    MyModule(n_classes=4),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.01,\n",
    "    max_epochs=15,\n",
    "    batch_size=1024,\n",
    "    #train_split=predefined_split(Dataset({\"x1\": x_features_cwt_val, \"x2\": x_features_rr_val}, y_class_val)),\n",
    "    verbose=1,\n",
    "    #device=\"cuda\",\n",
    "    callbacks=callbacks,\n",
    "    #iterator_train__shuffle=True,\n",
    "    optimizer__weight_decay=0,\n",
    "    criterion__weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5116, 20), (5116, 5, 100, 100), (5117,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9647, 0.0177, 0.0177])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor([4, 0, 0]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ------  -------\n",
      "      1        \u001b[36m4.6609\u001b[0m       \u001b[32m0.5322\u001b[0m      \u001b[35m0.5322\u001b[0m       \u001b[31m16.7924\u001b[0m  0.0100  39.0893\n",
      "      2        \u001b[36m1.8688\u001b[0m       0.2773      0.2773        \u001b[31m4.9232\u001b[0m  0.0100  36.6554\n",
      "      3        \u001b[36m1.2993\u001b[0m       0.4775      0.4775        \u001b[31m1.9350\u001b[0m  0.0100  38.5109\n",
      "      4        \u001b[36m1.1164\u001b[0m       0.4883      0.4883        1.9536  0.0100  37.3550\n",
      "      5        \u001b[36m1.0648\u001b[0m       \u001b[32m0.5488\u001b[0m      \u001b[35m0.5488\u001b[0m        \u001b[31m1.3885\u001b[0m  0.0100  37.1030\n",
      "      6        \u001b[36m0.9987\u001b[0m       0.5488      0.5488        \u001b[31m1.1633\u001b[0m  0.0010  38.0620\n",
      "      7        \u001b[36m0.9880\u001b[0m       \u001b[32m0.5605\u001b[0m      \u001b[35m0.5605\u001b[0m        \u001b[31m1.0894\u001b[0m  0.0010  37.9375\n",
      "      8        \u001b[36m0.9773\u001b[0m       \u001b[32m0.5625\u001b[0m      \u001b[35m0.5625\u001b[0m        \u001b[31m1.0527\u001b[0m  0.0010  39.2619\n",
      "      9        \u001b[36m0.9663\u001b[0m       \u001b[32m0.5664\u001b[0m      \u001b[35m0.5664\u001b[0m        \u001b[31m1.0294\u001b[0m  0.0010  39.1480\n",
      "     10        \u001b[36m0.9560\u001b[0m       0.5605      0.5605        \u001b[31m1.0128\u001b[0m  0.0010  38.1056\n",
      "     11        \u001b[36m0.9492\u001b[0m       0.5605      0.5605        \u001b[31m1.0097\u001b[0m  0.0001  39.6139\n",
      "     12        \u001b[36m0.9483\u001b[0m       0.5625      0.5625        \u001b[31m1.0074\u001b[0m  0.0001  38.5605\n",
      "     13        \u001b[36m0.9473\u001b[0m       0.5664      0.5664        \u001b[31m1.0055\u001b[0m  0.0001  39.3756\n",
      "     14        \u001b[36m0.9463\u001b[0m       \u001b[32m0.5703\u001b[0m      \u001b[35m0.5703\u001b[0m        \u001b[31m1.0040\u001b[0m  0.0001  40.5507\n",
      "     15        \u001b[36m0.9454\u001b[0m       \u001b[32m0.5732\u001b[0m      \u001b[35m0.5732\u001b[0m        \u001b[31m1.0026\u001b[0m  0.0001  37.5903\n",
      "CPU times: user 9min 47s, sys: 2min 45s, total: 12min 32s\n",
      "Wall time: 9min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (conv1): Conv2d(5, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pooling2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pooling3): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "    (fc1): Linear(in_features=84, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit({'x1': x_features_cwt, 'x2': x_features_rr}, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-142cbb14b885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cwt_cnn.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# Save clf\n",
    "#\n",
    "#with open('cwt_cnn_softmax.pkl', 'wb') as f:\n",
    "#    pickle.dump(clf, f)\n",
    "\n",
    "# load clf\n",
    "with open('cwt_cnn.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-122044083e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "clf.module.children()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_net = MyModule2()\n",
    "feature_net.children = clf.module.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 9.83 s, total: 32.2 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_train = feature_net(torch.Tensor(x_features_cwt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 3411/3411 [06:44<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 16s, sys: 37 s, total: 6min 53s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_cwt_test, x_rr_test, groups_test = load_data(X_test, train=False, n_samples=0, dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 3411/3411 [00:32<00:00, 105.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 3.82 s, total: 26.6 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_features_cwt_test, x_features_rr = aggregate_features(x_cwt_test, x_rr_test, groups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 6.91 s, total: 21.8 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_test = feature_net(torch.Tensor(x_features_cwt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(features_train.detach())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.array(features_train.detach())).to_csv('data/features_cwt_train.csv')\n",
    "pd.DataFrame(np.array(features_test.detach())).to_csv('data/features_cwt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3411, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.053884</td>\n",
       "      <td>0.527662</td>\n",
       "      <td>1.003648</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>1.065991</td>\n",
       "      <td>1.139568</td>\n",
       "      <td>0.577173</td>\n",
       "      <td>0.869370</td>\n",
       "      <td>0.646057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025725</td>\n",
       "      <td>1.056092</td>\n",
       "      <td>0.651778</td>\n",
       "      <td>0.985535</td>\n",
       "      <td>0.792129</td>\n",
       "      <td>0.829983</td>\n",
       "      <td>0.293246</td>\n",
       "      <td>1.006424</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.228594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667098</td>\n",
       "      <td>0.397549</td>\n",
       "      <td>0.671067</td>\n",
       "      <td>0.693171</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.552870</td>\n",
       "      <td>0.435969</td>\n",
       "      <td>0.425254</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.682516</td>\n",
       "      <td>0.588095</td>\n",
       "      <td>0.571876</td>\n",
       "      <td>0.282250</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.242213</td>\n",
       "      <td>0.696862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.496626</td>\n",
       "      <td>1.050576</td>\n",
       "      <td>1.038037</td>\n",
       "      <td>0.664625</td>\n",
       "      <td>1.444397</td>\n",
       "      <td>1.544839</td>\n",
       "      <td>2.184130</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.631937</td>\n",
       "      <td>...</td>\n",
       "      <td>2.031850</td>\n",
       "      <td>0.614756</td>\n",
       "      <td>0.558040</td>\n",
       "      <td>1.211306</td>\n",
       "      <td>1.081941</td>\n",
       "      <td>1.337465</td>\n",
       "      <td>1.207210</td>\n",
       "      <td>2.611131</td>\n",
       "      <td>0.672480</td>\n",
       "      <td>1.290483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.124188</td>\n",
       "      <td>0.661929</td>\n",
       "      <td>1.022232</td>\n",
       "      <td>0.595916</td>\n",
       "      <td>2.845088</td>\n",
       "      <td>1.314521</td>\n",
       "      <td>2.129592</td>\n",
       "      <td>0.593108</td>\n",
       "      <td>0.658319</td>\n",
       "      <td>...</td>\n",
       "      <td>2.258999</td>\n",
       "      <td>0.590005</td>\n",
       "      <td>0.556291</td>\n",
       "      <td>1.628519</td>\n",
       "      <td>0.631148</td>\n",
       "      <td>2.043719</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>2.160063</td>\n",
       "      <td>0.690835</td>\n",
       "      <td>2.499965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.736731</td>\n",
       "      <td>1.023247</td>\n",
       "      <td>0.727325</td>\n",
       "      <td>0.669825</td>\n",
       "      <td>1.163596</td>\n",
       "      <td>1.093796</td>\n",
       "      <td>1.248574</td>\n",
       "      <td>0.996106</td>\n",
       "      <td>0.644623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620245</td>\n",
       "      <td>0.910507</td>\n",
       "      <td>0.500981</td>\n",
       "      <td>1.127332</td>\n",
       "      <td>0.509404</td>\n",
       "      <td>1.279899</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>1.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.105614</td>\n",
       "      <td>0.527920</td>\n",
       "      <td>0.799911</td>\n",
       "      <td>0.898149</td>\n",
       "      <td>0.835801</td>\n",
       "      <td>0.383975</td>\n",
       "      <td>0.365174</td>\n",
       "      <td>1.375301</td>\n",
       "      <td>1.273502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500843</td>\n",
       "      <td>0.761378</td>\n",
       "      <td>0.441834</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>0.447509</td>\n",
       "      <td>0.223884</td>\n",
       "      <td>0.766456</td>\n",
       "      <td>0.683172</td>\n",
       "      <td>0.273357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.476705</td>\n",
       "      <td>1.283704</td>\n",
       "      <td>1.198632</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>1.449704</td>\n",
       "      <td>2.024672</td>\n",
       "      <td>1.704568</td>\n",
       "      <td>0.932451</td>\n",
       "      <td>0.678186</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066629</td>\n",
       "      <td>0.454198</td>\n",
       "      <td>0.568291</td>\n",
       "      <td>0.922337</td>\n",
       "      <td>0.877432</td>\n",
       "      <td>1.549912</td>\n",
       "      <td>1.212893</td>\n",
       "      <td>2.627507</td>\n",
       "      <td>0.706777</td>\n",
       "      <td>1.677669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.904392</td>\n",
       "      <td>1.039677</td>\n",
       "      <td>1.429466</td>\n",
       "      <td>0.608672</td>\n",
       "      <td>2.027883</td>\n",
       "      <td>1.678837</td>\n",
       "      <td>1.536985</td>\n",
       "      <td>0.687359</td>\n",
       "      <td>0.631743</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972809</td>\n",
       "      <td>0.158918</td>\n",
       "      <td>0.556390</td>\n",
       "      <td>1.000433</td>\n",
       "      <td>0.661309</td>\n",
       "      <td>1.904604</td>\n",
       "      <td>0.977114</td>\n",
       "      <td>2.013922</td>\n",
       "      <td>0.685082</td>\n",
       "      <td>2.252279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.270781</td>\n",
       "      <td>0.238646</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>2.391544</td>\n",
       "      <td>0.622831</td>\n",
       "      <td>0.709428</td>\n",
       "      <td>1.205754</td>\n",
       "      <td>0.555951</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560009</td>\n",
       "      <td>1.322023</td>\n",
       "      <td>0.727949</td>\n",
       "      <td>0.494784</td>\n",
       "      <td>1.314536</td>\n",
       "      <td>0.537894</td>\n",
       "      <td>0.167302</td>\n",
       "      <td>3.345844</td>\n",
       "      <td>0.565081</td>\n",
       "      <td>2.280358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.659825</td>\n",
       "      <td>0.646650</td>\n",
       "      <td>0.537403</td>\n",
       "      <td>0.770553</td>\n",
       "      <td>0.367418</td>\n",
       "      <td>0.347055</td>\n",
       "      <td>0.404829</td>\n",
       "      <td>1.635380</td>\n",
       "      <td>0.848491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830005</td>\n",
       "      <td>1.196949</td>\n",
       "      <td>0.700206</td>\n",
       "      <td>0.875473</td>\n",
       "      <td>0.632929</td>\n",
       "      <td>1.092206</td>\n",
       "      <td>0.215831</td>\n",
       "      <td>0.451516</td>\n",
       "      <td>0.695448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0  1.053884  0.527662  1.003648  0.649300  1.065991  1.139568   \n",
       "1           1  0.667098  0.397549  0.671067  0.693171  0.637909  0.552870   \n",
       "2           2  2.496626  1.050576  1.038037  0.664625  1.444397  1.544839   \n",
       "3           3  3.124188  0.661929  1.022232  0.595916  2.845088  1.314521   \n",
       "4           4  1.736731  1.023247  0.727325  0.669825  1.163596  1.093796   \n",
       "5           5  1.105614  0.527920  0.799911  0.898149  0.835801  0.383975   \n",
       "6           6  2.476705  1.283704  1.198632  0.615576  1.449704  2.024672   \n",
       "7           7  2.904392  1.039677  1.429466  0.608672  2.027883  1.678837   \n",
       "8           8  2.270781  0.238646  1.043478  0.618117  2.391544  0.622831   \n",
       "9           9  0.659825  0.646650  0.537403  0.770553  0.367418  0.347055   \n",
       "\n",
       "          6         7         8  ...        54        55        56        57  \\\n",
       "0  0.577173  0.869370  0.646057  ...  1.025725  1.056092  0.651778  0.985535   \n",
       "1  0.435969  0.425254  0.628000  ...  0.000000  0.022356  0.682516  0.588095   \n",
       "2  2.184130  1.021845  0.631937  ...  2.031850  0.614756  0.558040  1.211306   \n",
       "3  2.129592  0.593108  0.658319  ...  2.258999  0.590005  0.556291  1.628519   \n",
       "4  1.248574  0.996106  0.644623  ...  0.742766  0.000000  0.620245  0.910507   \n",
       "5  0.365174  1.375301  1.273502  ...  0.000000  0.500843  0.761378  0.441834   \n",
       "6  1.704568  0.932451  0.678186  ...  2.066629  0.454198  0.568291  0.922337   \n",
       "7  1.536985  0.687359  0.631743  ...  1.972809  0.158918  0.556390  1.000433   \n",
       "8  0.709428  1.205754  0.555951  ...  1.560009  1.322023  0.727949  0.494784   \n",
       "9  0.404829  1.635380  0.848491  ...  0.830005  1.196949  0.700206  0.875473   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0  0.792129  0.829983  0.293246  1.006424  0.694418  0.228594  \n",
       "1  0.571876  0.282250  0.346580  0.242213  0.696862  0.000000  \n",
       "2  1.081941  1.337465  1.207210  2.611131  0.672480  1.290483  \n",
       "3  0.631148  2.043719  0.975908  2.160063  0.690835  2.499965  \n",
       "4  0.500981  1.127332  0.509404  1.279899  0.685811  1.425536  \n",
       "5  0.490314  0.447509  0.223884  0.766456  0.683172  0.273357  \n",
       "6  0.877432  1.549912  1.212893  2.627507  0.706777  1.677669  \n",
       "7  0.661309  1.904604  0.977114  2.013922  0.685082  2.252279  \n",
       "8  1.314536  0.537894  0.167302  3.345844  0.565081  2.280358  \n",
       "9  0.632929  1.092206  0.215831  0.451516  0.695448  0.000000  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/features_train.csv')\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 65)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash from here\n",
    "or not?\n",
    "no guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecificVsRestClassifier(TransformerMixin):\n",
    "    def __init__(self, clf, one_class):\n",
    "        self.clf = copy.deepcopy(clf)\n",
    "        self.one_class = one_class\n",
    "    \n",
    "    def split_one_vs_rest(self, y):\n",
    "        idx_one = np.where(y == self.one_class)[0]\n",
    "        idx_rest = np.where(y != self.one_class)[0]\n",
    "        return idx_one, idx_rest\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        idx_one, idx_rest = self.split_one_vs_rest(y)\n",
    "        y_one_vs_rest = np.zeros_like(y)\n",
    "        y_one_vs_rest[idx_one] = 1\n",
    "        \n",
    "        # Balance class weights\n",
    "        if type(self.clf) == skorch.classifier.NeuralNetClassifier:\n",
    "            n_samples = len(y_one_vs_rest)\n",
    "            print(n_samples, len(idx_rest), len(idx_one))\n",
    "            class_weight = n_samples / torch.tensor([len(idx_rest), len(idx_one)])\n",
    "            self.clf.estimator__weight = class_weight\n",
    "            print(f'set class weight to: {class_weight}')\n",
    "        else:\n",
    "            self.clf.class_weigth = 'balanced'\n",
    "        self.clf.fit(X, y_one_vs_rest)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise vs rest\n",
    "noise_vs_rest_net = NeuralNetClassifier(  # skorch is extensive package of pytorch for compatible with scikit-learn\n",
    "    MyModule(n_classes=2),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.01,\n",
    "    max_epochs=10,\n",
    "    batch_size=1024,\n",
    "    #train_split=predefined_split(Dataset({\"x1\": x1_test, \"x2\": x2_test}, y_test)),\n",
    "    verbose=1,\n",
    "    #device=\"cuda\",\n",
    "    callbacks=callbacks,\n",
    "    #iterator_train__shuffle=True,\n",
    "    optimizer__weight_decay=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134597 130108 4489\n",
      "set class weight to: tensor([ 1.0345, 29.9837])\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.1612\u001b[0m       \u001b[32m0.9687\u001b[0m      \u001b[35m0.5993\u001b[0m        \u001b[31m0.0991\u001b[0m  0.0100  63.0540\n",
      "      2        \u001b[36m0.1032\u001b[0m       \u001b[32m0.9690\u001b[0m      \u001b[35m0.6237\u001b[0m        \u001b[31m0.0930\u001b[0m  0.0100  61.2749\n",
      "      3        \u001b[36m0.0975\u001b[0m       \u001b[32m0.9691\u001b[0m      0.6161        \u001b[31m0.0907\u001b[0m  0.0100  61.3022\n",
      "      4        \u001b[36m0.0940\u001b[0m       \u001b[32m0.9696\u001b[0m      \u001b[35m0.6269\u001b[0m        \u001b[31m0.0895\u001b[0m  0.0100  61.3065\n",
      "      5        \u001b[36m0.0913\u001b[0m       0.9695      \u001b[35m0.6436\u001b[0m        \u001b[31m0.0889\u001b[0m  0.0100  61.1121\n",
      "      6        \u001b[36m0.0826\u001b[0m       \u001b[32m0.9708\u001b[0m      0.6391        \u001b[31m0.0862\u001b[0m  0.0010  61.2732\n",
      "      7        \u001b[36m0.0800\u001b[0m       \u001b[32m0.9715\u001b[0m      \u001b[35m0.6560\u001b[0m        \u001b[31m0.0856\u001b[0m  0.0010  61.0439\n",
      "      8        \u001b[36m0.0791\u001b[0m       \u001b[32m0.9716\u001b[0m      \u001b[35m0.6617\u001b[0m        \u001b[31m0.0853\u001b[0m  0.0010  61.0808\n",
      "      9        \u001b[36m0.0783\u001b[0m       0.9714      \u001b[35m0.6638\u001b[0m        \u001b[31m0.0849\u001b[0m  0.0010  61.1748\n",
      "     10        \u001b[36m0.0776\u001b[0m       0.9716      \u001b[35m0.6694\u001b[0m        \u001b[31m0.0846\u001b[0m  0.0010  61.3757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SpecificVsRestClassifier at 0x7fdfc959ea90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_vs_rest_clf = SpecificVsRestClassifier(noise_vs_rest_net, 3)\n",
    "noise_vs_rest_clf.fit({'x1': x_cwt_train, 'x2': x_rr_train}, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthy vs sick\n",
    "healthy_vs_sick_net = NeuralNetClassifier(  # skorch is extensive package of pytorch for compatible with scikit-learn\n",
    "    MyModule(n_classes=2),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.01,\n",
    "    max_epochs=10,\n",
    "    batch_size=1024,\n",
    "    #train_split=predefined_split(Dataset({\"x1\": x1_test, \"x2\": x2_test}, y_test)),\n",
    "    verbose=1,\n",
    "    #device=\"cuda\",\n",
    "    callbacks=callbacks,\n",
    "    #iterator_train__shuffle=True,\n",
    "    optimizer__weight_decay=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130108 55700 74408\n",
      "set class weight to: tensor([2.3359, 1.7486])\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.5924\u001b[0m       \u001b[32m0.7333\u001b[0m      \u001b[35m0.6995\u001b[0m        \u001b[31m0.5466\u001b[0m  0.0100  60.1786\n",
      "      2        \u001b[36m0.5444\u001b[0m       \u001b[32m0.7375\u001b[0m      \u001b[35m0.7047\u001b[0m        0.5483  0.0100  59.3332\n",
      "      3        \u001b[36m0.5294\u001b[0m       \u001b[32m0.7479\u001b[0m      \u001b[35m0.7227\u001b[0m        \u001b[31m0.5260\u001b[0m  0.0100  58.8817\n",
      "      4        \u001b[36m0.5188\u001b[0m       \u001b[32m0.7499\u001b[0m      \u001b[35m0.7269\u001b[0m        \u001b[31m0.5211\u001b[0m  0.0100  58.8047\n",
      "      5        \u001b[36m0.5105\u001b[0m       \u001b[32m0.7507\u001b[0m      \u001b[35m0.7283\u001b[0m        0.5244  0.0100  58.7173\n",
      "      6        \u001b[36m0.4900\u001b[0m       \u001b[32m0.7777\u001b[0m      \u001b[35m0.7640\u001b[0m        \u001b[31m0.4840\u001b[0m  0.0010  58.6170\n",
      "      7        \u001b[36m0.4804\u001b[0m       \u001b[32m0.7793\u001b[0m      \u001b[35m0.7662\u001b[0m        \u001b[31m0.4815\u001b[0m  0.0010  58.7483\n",
      "      8        \u001b[36m0.4766\u001b[0m       \u001b[32m0.7794\u001b[0m      \u001b[35m0.7663\u001b[0m        \u001b[31m0.4799\u001b[0m  0.0010  58.5952\n",
      "      9        \u001b[36m0.4735\u001b[0m       \u001b[32m0.7800\u001b[0m      \u001b[35m0.7672\u001b[0m        \u001b[31m0.4785\u001b[0m  0.0010  58.7367\n",
      "     10        \u001b[36m0.4707\u001b[0m       \u001b[32m0.7813\u001b[0m      \u001b[35m0.7686\u001b[0m        \u001b[31m0.4773\u001b[0m  0.0010  58.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SpecificVsRestClassifier at 0x7fdfb8392250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_noise, idx_rest = noise_vs_rest_clf.split_one_vs_rest(y_train)\n",
    "\n",
    "x_cwt_train_rest = x_cwt_train[idx_rest]\n",
    "x_rr_train_rest = x_rr_train[idx_rest]\n",
    "y_train_rest = y_train[idx_rest]\n",
    "\n",
    "healthy_vs_sick_clf = SpecificVsRestClassifier(healthy_vs_sick_net, 0)\n",
    "healthy_vs_sick_clf.fit({'x1': x_cwt_train_rest, 'x2': x_rr_train_rest}, y_train_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sick vs sick\n",
    "sick_vs_sick_net = NeuralNetClassifier(  # skorch is extensive package of pytorch for compatible with scikit-learn\n",
    "    MyModule(n_classes=2),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.01,\n",
    "    max_epochs=10,\n",
    "    batch_size=1024,\n",
    "    #train_split=predefined_split(Dataset({\"x1\": x1_test, \"x2\": x2_test}, y_test)),\n",
    "    verbose=1,\n",
    "    #device=\"cuda\",\n",
    "    callbacks=callbacks,\n",
    "    #iterator_train__shuffle=True,\n",
    "    optimizer__weight_decay=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55700 49814 5886\n",
      "set class weight to: tensor([1.1182, 9.4631])\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.4262\u001b[0m       \u001b[32m0.8952\u001b[0m      \u001b[35m0.4881\u001b[0m        \u001b[31m0.3016\u001b[0m  0.0100  25.5885\n",
      "      2        \u001b[36m0.2627\u001b[0m       \u001b[32m0.8958\u001b[0m      \u001b[35m0.5016\u001b[0m        \u001b[31m0.2826\u001b[0m  0.0100  25.5187\n",
      "      3        \u001b[36m0.2438\u001b[0m       \u001b[32m0.9040\u001b[0m      \u001b[35m0.6055\u001b[0m        \u001b[31m0.2654\u001b[0m  0.0100  25.4798\n",
      "      4        \u001b[36m0.2311\u001b[0m       \u001b[32m0.9056\u001b[0m      \u001b[35m0.6572\u001b[0m        \u001b[31m0.2570\u001b[0m  0.0100  25.4994\n",
      "      5        \u001b[36m0.2222\u001b[0m       \u001b[32m0.9125\u001b[0m      \u001b[35m0.6708\u001b[0m        \u001b[31m0.2552\u001b[0m  0.0100  25.3621\n",
      "      6        \u001b[36m0.2007\u001b[0m       \u001b[32m0.9151\u001b[0m      \u001b[35m0.6822\u001b[0m        \u001b[31m0.2098\u001b[0m  0.0010  25.5619\n",
      "      7        \u001b[36m0.1930\u001b[0m       \u001b[32m0.9157\u001b[0m      \u001b[35m0.6982\u001b[0m        \u001b[31m0.2088\u001b[0m  0.0010  25.5163\n",
      "      8        \u001b[36m0.1895\u001b[0m       \u001b[32m0.9168\u001b[0m      \u001b[35m0.7084\u001b[0m        \u001b[31m0.2077\u001b[0m  0.0010  25.3692\n",
      "      9        \u001b[36m0.1871\u001b[0m       \u001b[32m0.9182\u001b[0m      \u001b[35m0.7159\u001b[0m        \u001b[31m0.2068\u001b[0m  0.0010  25.2356\n",
      "     10        \u001b[36m0.1850\u001b[0m       \u001b[32m0.9200\u001b[0m      \u001b[35m0.7253\u001b[0m        \u001b[31m0.2057\u001b[0m  0.0010  25.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SpecificVsRestClassifier at 0x7fdfb947dee0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_healthy, idx_sick = healthy_vs_sick_clf.split_one_vs_rest(y_train_rest)\n",
    "\n",
    "x_cwt_train_sick = x_cwt_train[idx_sick]\n",
    "x_rr_train_sick = x_rr_train[idx_sick]\n",
    "y_train_sick = y_train[idx_sick]\n",
    "\n",
    "sick_vs_sick_clf = SpecificVsRestClassifier(healthy_vs_sick_net, 1)\n",
    "sick_vs_sick_clf.fit({'x1': x_cwt_train_sick, 'x2': x_rr_train_sick}, y_train_sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10\n",
    "y_pred = sick_vs_sick_clf.transform({'x1': x_cwt_val[:s], 'x2': x_rr_val[:s]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list({'x1': x_cwt_val[:10], 'x2': x_rr_val[:10]}.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = np.empty(len(X))\n",
    "idx = np.where(y_pred == 0)[0]\n",
    "y_result[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patients(clfs, X):\n",
    "    nsamples = len(list(X.values())[0])\n",
    "    y_result = - np.ones(nsamples)\n",
    "    X_samples = X\n",
    "    \n",
    "    for clf in clfs:\n",
    "        y_pred = clf.transform(X_samples)\n",
    "        idx_one = np.where(y_pred == 1)[0]\n",
    "        idx_rest = np.where(y_pred == 0)[0]\n",
    "        \n",
    "        y_result[idx_one] = clf.one_class\n",
    "        \n",
    "        if len(idx_rest) == 0:\n",
    "            break\n",
    "        \n",
    "        X_samples = {'x1': X_samples['x1'][idx_rest], 'x2': X_samples['x2'][idx_rest]}\n",
    "        \n",
    "    \n",
    "    idx_last = np.where(y_result < 0)[0]\n",
    "    y_result[idx_last] = clfs[-1].one_class\n",
    "    return y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39434616388690474"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = [noise_vs_rest_clf, healthy_vs_sick_clf, sick_vs_sick_clf]\n",
    "y_result = predict_patients(clfs, {'x1': x_cwt_val, 'x2': x_rr_val})\n",
    "df_preds = pd.DataFrame({'groups': groups_val, 'preds': y_result, 'truth': y_val})\n",
    "df_preds_grouped = df_preds.groupby('groups').agg(lambda x: x.value_counts().index[0])\n",
    "y_preds = df_preds_grouped.preds.values\n",
    "y_val_grouped = df_preds_grouped.truth.values\n",
    "f1_score(y_val_grouped, y_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5378189656813283"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_filter = np.where(y_val != 3)[0]\n",
    "X_val_filtered = {'x1': x_cwt_val[idx_filter], 'x2': x_rr_val[idx_filter]}\n",
    "y_val_filtered = y_val[idx_filter]\n",
    "groups_val_filtered = groups_val[idx_filter]\n",
    "\n",
    "clfs = [healthy_vs_sick_clf, sick_vs_sick_clf]\n",
    "\n",
    "y_result = predict_patients(clfs, X_val_filtered)\n",
    "df_preds = pd.DataFrame({'groups': groups_val_filtered, 'preds': y_result, 'truth': y_val_filtered})\n",
    "df_preds_grouped = df_preds.groupby('groups').agg(lambda x: x.value_counts().index[0])\n",
    "y_preds = df_preds_grouped.preds.values\n",
    "y_val_grouped = df_preds_grouped.truth.values\n",
    "f1_score(y_val_grouped, y_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ------  -------\n",
      "      1        \u001b[36m1.3530\u001b[0m       \u001b[32m0.4871\u001b[0m      \u001b[35m0.4246\u001b[0m        \u001b[31m1.1630\u001b[0m  0.0010  64.3184\n",
      "      2        \u001b[36m1.1418\u001b[0m       \u001b[32m0.5365\u001b[0m      \u001b[35m0.4531\u001b[0m        \u001b[31m1.1017\u001b[0m  0.0010  62.3102\n",
      "      3        \u001b[36m1.0772\u001b[0m       \u001b[32m0.5598\u001b[0m      \u001b[35m0.4714\u001b[0m        \u001b[31m1.0623\u001b[0m  0.0010  62.1270\n",
      "      4        \u001b[36m1.0374\u001b[0m       \u001b[32m0.5759\u001b[0m      \u001b[35m0.4904\u001b[0m        \u001b[31m1.0371\u001b[0m  0.0010  61.7806\n",
      "      5        \u001b[36m1.0096\u001b[0m       \u001b[32m0.5925\u001b[0m      \u001b[35m0.5026\u001b[0m        \u001b[31m1.0212\u001b[0m  0.0010  61.6510\n",
      "      6        \u001b[36m0.9664\u001b[0m       0.5836      0.4906        \u001b[31m1.0192\u001b[0m  0.0001  62.0657\n",
      "      7        \u001b[36m0.9461\u001b[0m       0.5833      0.4925        \u001b[31m1.0138\u001b[0m  0.0001  61.7416\n",
      "      8        \u001b[36m0.9405\u001b[0m       0.5839      0.4933        \u001b[31m1.0108\u001b[0m  0.0001  62.2257\n",
      "      9        \u001b[36m0.9362\u001b[0m       0.5842      0.4943        \u001b[31m1.0081\u001b[0m  0.0001  61.7397\n",
      "     10        \u001b[36m0.9323\u001b[0m       0.5851      0.4955        \u001b[31m1.0054\u001b[0m  0.0001  62.0358\n",
      "     11        \u001b[36m0.9242\u001b[0m       0.5848      0.4938        1.0081  0.0000  63.1829\n",
      "     12        \u001b[36m0.9236\u001b[0m       0.5848      0.4943        1.0078  0.0000  63.2989\n",
      "     13        \u001b[36m0.9232\u001b[0m       0.5850      0.4947        1.0075  0.0000  63.2936\n",
      "     14        \u001b[36m0.9227\u001b[0m       0.5849      0.4949        1.0072  0.0000  63.0832\n",
      "     15        \u001b[36m0.9223\u001b[0m       0.5847      0.4950        1.0069  0.0000  62.8674\n",
      "     16        \u001b[36m0.9214\u001b[0m       0.5845      0.4946        1.0072  0.0000  62.8063\n",
      "     17        \u001b[36m0.9213\u001b[0m       0.5845      0.4946        1.0072  0.0000  63.1608\n",
      "     18        \u001b[36m0.9213\u001b[0m       0.5846      0.4948        1.0071  0.0000  62.7370\n",
      "     19        \u001b[36m0.9213\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.9062\n",
      "     20        \u001b[36m0.9212\u001b[0m       0.5844      0.4947        1.0071  0.0000  62.6574\n",
      "     21        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.6755\n",
      "     22        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.4714\n",
      "     23        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.7327\n",
      "     24        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  63.0767\n",
      "     25        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  63.0160\n",
      "     26        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.8906\n",
      "     27        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.7758\n",
      "     28        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.5421\n",
      "     29        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.3593\n",
      "     30        \u001b[36m0.9211\u001b[0m       0.5845      0.4947        1.0071  0.0000  62.4665\n",
      "CPU times: user 53min 53s, sys: 15.9 s, total: 54min 9s\n",
      "Wall time: 31min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pooling2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pooling3): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "    (fc1): Linear(in_features=68, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "net.fit({'x1': x_cwt_train, 'x2': x_rr_train}, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cwt_cnn_cleaned.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cwt_test, x_rr_test, groups = load_data('data/X_test.csv', '', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123542, 1, 100, 100), (123542, 4), (123542,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cwt_test.shape, x_rr_test.shape, groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_beat = net.predict({'x1':x_cwt_val, 'x2': x_rr_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45504,), (1280,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape, y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'groups': groups_val, 'preds': preds_beat, 'truth': y_val})\n",
    "df_preds_grouped = df_preds.groupby('groups').agg(lambda x: x.value_counts().index[0])\n",
    "y_preds = df_preds_grouped.preds.values\n",
    "y_val_grouped = df_preds_grouped.truth.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6766670613804765"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_val_grouped, y_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    3,    5,    8,   18,   19,   21,   24,   29,   32,   34,\n",
       "         37,   38,   39,   40,   45,   48,   59,   60,   61,   64,   65,\n",
       "         68,   72,   74,   77,   78,   84,   88,   97,   99,  101,  106,\n",
       "        108,  113,  115,  117,  120,  126,  135,  136,  144,  145,  146,\n",
       "        149,  150,  155,  156,  157,  159,  161,  168,  171,  178,  179,\n",
       "        182,  184,  186,  189,  198,  199,  201,  203,  204,  211,  212,\n",
       "        216,  218,  220,  222,  223,  227,  229,  230,  232,  235,  237,\n",
       "        238,  242,  247,  254,  257,  259,  264,  266,  270,  273,  276,\n",
       "        278,  280,  284,  285,  286,  287,  289,  290,  291,  293,  294,\n",
       "        297,  298,  299,  300,  304,  306,  308,  316,  318,  320,  321,\n",
       "        325,  327,  330,  333,  337,  343,  348,  349,  351,  359,  365,\n",
       "        367,  369,  372,  375,  380,  389,  393,  398,  400,  405,  406,\n",
       "        407,  413,  417,  420,  426,  427,  429,  430,  431,  432,  433,\n",
       "        435,  437,  443,  448,  452,  454,  455,  457,  462,  466,  467,\n",
       "        468,  469,  473,  478,  481,  484,  485,  488,  489,  491,  493,\n",
       "        494,  497,  498,  502,  503,  504,  508,  519,  524,  525,  526,\n",
       "        527,  530,  534,  536,  538,  541,  545,  548,  549,  551,  552,\n",
       "        553,  556,  559,  561,  575,  577,  578,  584,  593,  596,  602,\n",
       "        610,  612,  616,  619,  622,  624,  628,  632,  641,  642,  643,\n",
       "        646,  648,  654,  655,  658,  659,  660,  663,  675,  681,  685,\n",
       "        686,  688,  689,  695,  699,  705,  708,  709,  710,  716,  717,\n",
       "        727,  728,  732,  734,  735,  739,  740,  741,  744,  746,  747,\n",
       "        748,  749,  751,  752,  754,  759,  764,  767,  768,  770,  773,\n",
       "        775,  779,  783,  786,  787,  788,  791,  794,  797,  800,  804,\n",
       "        810,  815,  816,  822,  827,  839,  840,  842,  850,  853,  857,\n",
       "        859,  860,  863,  868,  873,  878,  881,  883,  884,  887,  896,\n",
       "        898,  899,  901,  903,  905,  907,  917,  921,  924,  925,  932,\n",
       "        935,  948,  951,  956,  957,  961,  962,  964,  970,  974,  975,\n",
       "        977,  979,  980,  984,  987,  995,  996,  997,  998, 1001, 1009,\n",
       "       1010, 1013, 1014, 1023, 1027, 1028, 1029, 1031, 1032, 1033, 1034,\n",
       "       1035, 1036, 1037, 1042, 1045, 1046, 1050, 1052, 1055, 1056, 1059,\n",
       "       1064, 1066, 1072, 1078, 1079, 1091, 1092, 1093, 1096, 1097, 1101,\n",
       "       1107, 1112, 1115, 1116, 1117, 1121, 1122, 1128, 1131, 1141, 1142,\n",
       "       1143, 1145, 1146, 1147, 1152, 1154, 1156, 1157, 1158, 1159, 1161,\n",
       "       1165, 1166, 1167, 1168, 1169, 1171, 1172, 1175, 1185, 1186, 1192,\n",
       "       1193, 1197, 1201, 1206, 1207, 1211, 1212, 1213, 1215, 1216, 1219,\n",
       "       1221, 1222, 1225, 1226, 1228, 1230, 1232, 1236, 1237, 1239, 1242,\n",
       "       1243, 1244, 1247, 1248, 1253, 1254, 1259, 1262, 1264, 1268, 1277,\n",
       "       1279])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_clf = np.where(y_preds != y_val_grouped)[0]\n",
    "miss_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spring21JodokVieli)",
   "language": "python",
   "name": "spring21jodokvieli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
