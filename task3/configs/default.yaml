application:
  log_level: 'DEBUG' # one of ['TRACE', 'DEBUG', 'INFO', 'SUCCESS', 'WARNING', 'ERROR', 'CRITICAL']

data:
  path: data/data_roi # data folder path (no trailing slash)
  dataset_training_path: expert_train_padded.pkl # path within data folder (no slashes)
  dataset_submission_path: expert_test_padded.pkl

  exclude_samples: null # if null, loads all 65 samples
  include_samples: null
  dataset: expert # possible values: amateur, expert, null (null includes both datasets; training only)
  only_annotated: True # If true, dataloader only loads frames with labels (training only)
  transformations: True # applies composition of transforms (toPIL, )
  test_split: 0 # some guidance on choosing optimal splits: https://stackoverflow.com/a/13623707/3142478; size of training (incl. validation) set is 1-test_split
  validation_split: 0.2 # size of validation set (calculated after splitting the training set into test and train sets)

  batch_size: 8 # training only
  orig_in_dl: True # includes the original frame in each item generated by the dataloader (useful for debugging and prediction quality checks); default: False

  resy: 224 # the output of the data loader gets scaled to these dimensions
  resx: 224

  asp_y: 1
  asp_x: 1 # desired aspect ratio; ideally, this matches the aspect ratio of resy/resx

model:
  smp-unet: # https://segmentation-modelspytorch.readthedocs.io/en/latest/
    encoder_name: resnet34
    encoder_weights: null
    in_channels: 1
    classes: 2
    encoder_depth: 5
    decoder_use_batchnorm: True
    decoder_channels: [256, 128, 64, 32, 16]
    decoder_attention_type: null
    activation: sigmoid
    aux_params: null

  simple-unet: null

training: # only batch sized used, so far
  optimizer: Adam
  lr: 0.00005
  momentum: 0.9
  #sgd:
  #lr: 0.0001
  loss: bcewithlogits # BCEWithLogitsLoss binary / iou on pytorch: https://stackoverflow.com/questions/48260415/pytorch-how-to-compute-iou-jaccard-index-for-semantic-segmentation
  num_classes: 2 # should be the same as classes in smp-unet
  epochs: 1
  batch_size: 10
  num_workers: 1  # default is 0: running on main process, hogasrv007 has 8 cores and 8 threads / core -> +1 might be enough speed up
                  # TODO Test speedup
                  # The num_workers attribute tells the data loader instance how many sub-processes to use for data loading.

transforms:
  elastic_transform__alpha: 1.5
  elastic_transform__sigma: 0.08
  elastic_transform__alpha_affine: 0.08
  elastic_transform__p: 0.8
  random_affine__translate: [0.1, 0.1]
  random_affine__scale: 1.2
  random_perspective__distortion_scale: 0.1
  color_jitter__brightness: 0.1
  color_jitter__contrast: 0.1
  color_jitter__saturation: 0.1