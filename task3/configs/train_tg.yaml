application:
  log_level: 'DEBUG' # one of ['TRACE', 'DEBUG', 'INFO', 'SUCCESS', 'WARNING', 'ERROR', 'CRITICAL']

device: cpu

data:
  path: data # data folder path (no trailing slash)
  dataset_training_file: train.pkl # path within data folder (no slashes)
  dataset_test_file: test.pkl

  exclude_samples: null # if null, loads all 65 samples
  include_samples: null
  dataset: null # possible values: amateur, expert, null (null includes both datasets; training only)
  only_annotated: True # If true, dataloader only loads frames with labels (training only)
  transformations: True # applies composition of transforms (toPIL, )
  test_split: 0 # some guidance on choosing optimal splits: https://stackoverflow.com/a/13623707/3142478; size of training (incl. validation) set is 1-test_split
  validation_split: 0.2 # size of validation set (calculated after splitting the training set into test and train sets)

  batch_size: 8 # training only
  orig_in_dl: True # includes the original frame in each item generated by the dataloader (useful for debugging and prediction quality checks); default: False

  resy: 40 # the output of the data loader gets scaled to these dimensions
  resx: 40

  asp_y: 1
  asp_x: 1 # desired aspect ratio; ideally, this matches the aspect ratio of resy/resx

model:
  # currently only one model is supported
  smp-unet: # https://segmentation-modelspytorch.readthedocs.io/en/latest/
    encoder_name: resnet34
    encoder_weights: null
    in_channels: 1
    classes: 1 # we only need one output channel showing True/False
    encoder_depth: 5
    decoder_use_batchnorm: True
    decoder_channels: [256, 128, 64, 32, 16]
    decoder_attention_type: null
    activation: sigmoid
    aux_params: null

training: # only batch sized used, so far
  optimizer: Adam
  lr: 0.0005 # was set to 0.00005 before
  momentum: 0.9
#https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html and #https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html
  lr_scheduler: steplr # not implemented yet; schedule lr, use steplr or reduceonplateau
  #sgd:
  #lr: 0.0001
  loss: bce # use BCE() or jaccard loss (as this is a direct proxy to IoU); choose between BCEWithLogits(), BCE(). JaccardLoss(), DiceLoss()
  metric: pytorch_iou # TODO add evaluation method from project page
  epochs: 10
  num_workers: 8  # default is 0: running on main process, hogasrv007 has 8 cores and 8 threads / core -> +1 might be enough speed up
  save_path: runs/mitrial_valve_training_6 # (no trailing slash); where to save models to and store training/validation metrics (scalars)