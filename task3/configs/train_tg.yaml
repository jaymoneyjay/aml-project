application:
  log_level: 'DEBUG' # one of ['TRACE', 'DEBUG', 'INFO', 'SUCCESS', 'WARNING', 'ERROR', 'CRITICAL']

device: cuda # cpu or cuda (for gpu); train on cpu or gpu

data:
  path: data/data_roi # data folder path (no trailing slash)
  dataset_training_path: expert_train_padded.pkl # path within data folder (no slashes)
  dataset_submission_path: expert_test_padded.pkl

  resy: 224 # the output of the data loader gets scaled to these dimensions
  resx: 224

  asp_y: 1  # 1,1 raises an error RuntimeError: When creating a new ROI box mask, the coordinates leave the valid coordinate range. --> see TODO in img_utils.py
  asp_x: 1 # desired aspect ratio; ideally, this matches the aspect ratio of resy/resx

  # if null, loads all 65 samples
  exclude_samples: null
  include_samples: null
  dataset: null # possible values: amateur, expert, null (null includes both datasets; training only)
  only_annotated: True # If true, dataloader only loads frames with labels (training only)
  transformations: True # applies composition of transforms (toPIL, )
  validation_split: 0.2 # size of validation set, size of training set is 1-val_size
  test_split: 0
  batch_size: 1 # training only

model:
  # currently only one model is supported
  name: smp-unet-plusplus #deepv3+ needs drop_last=True in datalaoder in config.py
  params:
    encoder_name: resnet101
    encoder_weights: null
    in_channels: 1
    classes: 1 # we only need one output channel sowing True/False
    encoder_depth: 5
    decoder_use_batchnorm: True
    decoder_channels: [512, 256, 128, 64, 32]
    decoder_attention_type: scse #scse: boosting meaningful features while suppressing weak ones.
    activation: sigmoid
    aux_params: null
  #name: smp-unet-plusplus # Decoder of Unet++ is more complex than in usual Unet.
  #encoder_name: efficientnet-b3
  #encoder_weights: null #imagenet
  #in_channels: 1
  #classes: 1 # we only need one output channel showing True/False
  #encoder_depth: 5
  #decoder_use_batchnorm: True
  #decoder_channels: [256, 128, 64, 32, 16]
  #decoder_attention_type: null # scse
  #activation: sigmoid
  #aux_params: null

  #name: smp-unet-deepv3+ # Decoder of Unet++ is more complex than in usual Unet.
  #encoder_name: resnet101
  #encoder_weights: null #imagenet
  #in_channels: 1
  #classes: 1 # we only need one output channel showing True/False
  #encoder_depth: 5
  #decoder_use_batchnorm: True
  #decoder_channels: [256, 128, 64, 32, 16]
  #decoder_attention_type: null # scse
  #activation: sigmoid
  #aux_params: null
training: # only batch sized used, so far
  optimizer: Adam
  lr: 0.005 # was set to 0.00005 before
  momentum: 0.9
#https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html and #https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html
  lr_scheduler: steplr #schedule lr, use steplr or reduceonplateau
  #sgd:
  #lr: 0.0001
  loss: jaccard # use BCE() or jaccard loss (as this is a direct proxy to IoU); choose between BCEWithLogits(), BCE(). JaccardLoss(), DiceLoss()
  metric: pytorch_iou # TODO add evaluation method from project page
  epochs: 400
  num_workers: 8  # default is 0: running on main process, hogasrv007 has 8 cores and 8 threads / core -> +1 might be enough speed up
  save_path: runs/mv_training_15 # (no trailing slash); where to save models to and store training/validation metrics (scalars)
run_notes: 'unet++ with resnet34 and amateur net, testsplit 0.0, image transformations higher values, batchsize 10'

transforms:
  elastic_transform__alpha: 2
  elastic_transform__sigma: 0.08
  elastic_transform__alpha_affine: 0.08
  elastic_transform__p: 0.8
  random_affine__translate: [0.1, 0.1] # don't change, will error out in training
  random_affine__scale: 1.2
  random_perspective__distortion_scale: 0.3
  color_jitter__brightness: 0.3
  color_jitter__contrast: 0.3
  color_jitter__saturation: 0.3
